[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "data_engineering_realtime_pipeline"
version = "0.1.0"
description = "Multi-cloud data engineering pipeline framework supporting multiple orchestrators and data sources"
authors = [
    {name = "Your Name", email = "your.email@example.com"}
]
readme = "README.md"
requires-python = ">=3.10"
license = {text = "MIT"}
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Topic :: Software Development :: Libraries",
]
dependencies = [
    # Core dependencies
    "requests>=2.31.0",
    "pydantic>=2.5.3",
    "python-dotenv>=1.0.0",
    "pandas>=2.0.0",
    "pyarrow>=10.0.0",
    "duckdb>=0.9.0",
    
    # Data-specific libraries
    "gtfs-realtime-bindings>=1.0.0",
    "protobuf>=4.24.4",
    "confluent-kafka>=2.1.0",
    
    # Database connectors
    "sqlalchemy>=1.4.49,<2.0.0",  # Changed to be compatible with Airflow 3.0
    "psycopg2-binary>=2.9.0",
    
    # Data formats
    "fastavro>=1.7.0",
]

[project.optional-dependencies]
# Cloud provider dependencies
aws = [
    "boto3>=1.28.0",
    "awscli>=1.29.0",
]

gcp = [
    "google-cloud-storage>=2.10.0",
    "google-cloud-bigquery>=3.12.0",
    "google-auth>=2.22.0",
]

azure = [
    "azure-storage-blob>=12.19.0",
    "azure-identity>=1.15.0",
]

# Orchestrators
airflow = [
    "apache-airflow>=3.0.0",
    "apache-airflow-providers-postgres>=5.0.0",
    "apache-airflow-providers-apache-kafka>=1.1.0",
    "apache-airflow-providers-dbt-cloud>=3.5.0",
    "apache-airflow-providers-slack>=8.0.0",
    "apache-airflow-providers-http>=4.5.0",
    "apache-airflow-providers-amazon>=6.0.0",
    "apache-airflow-providers-google>=10.0.0",
    "apache-airflow-providers-microsoft-azure>=6.0.0",
    "apache-airflow-providers-standard>=1.0.0",
]

dbt = [
    "dbt-core>=1.5.0",
    "dbt-duckdb>=1.5.0",
    "dbt-postgres>=1.5.0",
]

kestra = [
    # Kestra is primarily Java-based, but we include Python deps for scripting
    "requests>=2.31.0",
    "pyyaml>=6.0",
]

# Data formats and protocols
avro = [
    "fastavro>=1.7.0",
]

kafka = [
    "confluent-kafka>=2.1.0",
]

# Development and testing
dev = [
    "black>=23.3.0",
    "mypy>=1.3.0",
    "pytest>=7.3.1",
    "pytest-cov>=4.1.0",
    "ruff>=0.0.271",
    "flake8>=6.0.0",
    "pre-commit>=3.3.3",
    "invoke>=2.0.0",
    "python-dotenv>=1.0.0",
]

# Environment-specific configurations
development = [
    "data_engineering_realtime_pipeline[aws,gcp,azure,airflow,dbt,avro,kafka,dev]",
    "jupyter>=1.0.0",
    "ipython>=8.12.0",
]

staging = [
    "data_engineering_realtime_pipeline[aws,gcp,azure,airflow,dbt,avro,kafka]",
]

production = [
    "data_engineering_realtime_pipeline[aws,gcp,azure,airflow,dbt,avro,kafka]",
]

# Simplify to just airflow_dev
airflow_dev = [
    "apache-airflow>=3.0.0",
    "data_engineering_realtime_pipeline[aws,gcp,azure,dbt,avro,kafka,dev]",
]

kestra_dev = [
    "data_engineering_realtime_pipeline[aws,gcp,azure,dbt,avro,kafka,kestra,dev]",
]

# Full installation - ensuring we don't reference airflow2
all = [
    "data_engineering_realtime_pipeline[aws,gcp,azure,airflow,dbt,kestra,avro,kafka,dev]",
]

[project.urls]
"Source Code" = "https://github.com/yourusername/data_engineering_realtime_pipeline"
"Bug Tracker" = "https://github.com/yourusername/data_engineering_realtime_pipeline/issues"
"Documentation" = "https://github.com/yourusername/data_engineering_realtime_pipeline/blob/main/README.md"

[tool.mypy]
python_version = "3.10"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_incomplete_defs = true
check_untyped_defs = true
disallow_untyped_decorators = true
ignore_missing_imports = true

[tool.black]
line-length = 100
target-version = ['py310']
include = '\.pyi?$'
exclude = '''
/(
    \.git
  | \.hg
  | \.mypy_cache
  | \.tox
  | \.venv
  | _build
  | buck-out
  | build
  | dist
)/
'''

[tool.ruff]
line-length = 100
target-version = 'py310'
select = ['E', 'F', 'W', 'I']

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = "test_*.py"
python_functions = "test_*"
python_classes = "Test*"